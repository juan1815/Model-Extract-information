{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## libreries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1341,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pdfplumber\n",
    "import spacy\n",
    "from spacy.training import Example\n",
    "import random\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fecha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1342,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_date_str(text: str) -> str | None:\n",
    "    patterns = [\n",
    "        r\"(\\d{1,2})\\s*(?:de\\s*)?([A-Z]+)\\s*(?:de\\s*)?(\\d{4})\",\n",
    "        r\"(\\d{1,2})\\s+([A-Z]{3,})\\s+(\\d{4})\",\n",
    "    ]\n",
    "    month_map = {\n",
    "        \"ENE\": \"01\", \"FEB\": \"02\", \"MAR\": \"03\", \"ABR\": \"04\",\n",
    "        \"MAY\": \"05\", \"JUN\": \"06\", \"JUL\": \"07\", \"AGO\": \"08\",\n",
    "        \"SEP\": \"09\", \"OCT\": \"10\", \"NOV\": \"11\", \"DIC\": \"12\",\n",
    "        \"ENERO\": \"01\", \"FEBRERO\": \"02\", \"MARZO\": \"03\", \"ABRIL\": \"04\",\n",
    "        \"MAYO\": \"05\", \"JUNIO\": \"06\", \"JULIO\": \"07\", \"AGOSTO\": \"08\",\n",
    "        \"SEPTIEMBRE\": \"09\", \"OCTUBRE\": \"10\", \"NOVIEMBRE\": \"11\", \"DICIEMBRE\": \"12\"\n",
    "    }\n",
    "\n",
    "    for pattern in patterns:\n",
    "        match = re.search(pattern, text, re.IGNORECASE)\n",
    "        if match:\n",
    "            try:\n",
    "                day = match.group(1).zfill(2)\n",
    "                month = month_map.get(match.group(2).upper())\n",
    "                year = match.group(3)\n",
    "\n",
    "                if month:\n",
    "                    return f\"{day}/{month}/{year}\"\n",
    "            except ValueError:\n",
    "                continue\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1343,
   "metadata": {},
   "outputs": [],
   "source": [
    "def looks_like_date(candidate: str) -> bool:\n",
    "    \"\"\"\n",
    "    Verifica si 'candidate' se puede parsear como fecha \n",
    "    usando la función parse_date_str.\n",
    "    Retorna True si es una fecha válida, de lo contrario False.\n",
    "    \"\"\"\n",
    "    return parse_date_str(candidate) is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1344,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_spacy_date(spacy_fecha: str) -> str | None:\n",
    "    \"\"\"\n",
    "    Intenta parsear la fecha que spaCy devolvió y, si es válida,\n",
    "    retorna la versión normalizada (dd/mm/yyyy).\n",
    "    De lo contrario, retorna None.\n",
    "    \"\"\"\n",
    "    if not spacy_fecha:\n",
    "        return None\n",
    "    \n",
    "    parsed = parse_date_str(spacy_fecha)\n",
    "    return parsed  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extrae epigrafe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1345,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extraer_epigrafe(text: str, fecha_normalizada: str) -> str | None:\n",
    "    if fecha_normalizada:\n",
    "        pattern = rf\"{re.escape(fecha_normalizada)}.*?(POR\\s+MEDIO\\s+DE\\s+LA\\s+CUAL\\s+.*?)(?:\\.\\s*|\\n|EL\\s+CONGRESO)\"\n",
    "    else:\n",
    "        pattern = r\"(POR\\s+MEDIO\\s+DE\\s+LA\\s+CUAL\\s+.*?)(?:\\.\\s*|\\n|EL\\s+CONGRESO)\"\n",
    "\n",
    "    match = re.search(pattern, text, re.IGNORECASE | re.DOTALL)\n",
    "    if match:\n",
    "        return match.group(1).strip()\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tipo de ley "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1346,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_ocr_issues(text: str) -> str:\n",
    "    correcciones = {\n",
    "        \"NACiÓN\": \"NACIÓN\",\n",
    "        \"Colr,mbiana\": \"Colombiana\",\n",
    "        \"Perscnal\": \"Personal\",\n",
    "        \"AérEa\": \"Aérea\",\n",
    "        \"No1956\": \"No 1956\",\n",
    "        \"No.1956\": \"No. 1956\",\n",
    "        \"N°1956\": \"N° 1956\",\n",
    "        \"LEYNo\": \"LEY No\",\n",
    "        \"LEYNo.\": \"LEY No.\",\n",
    "        \"4JUN2019\": \"4 JUN 2019\",\n",
    "        \"Dadaen\": \"Dada en\"\n",
    "    }\n",
    "    for error, correccion in correcciones.items():\n",
    "        text = text.replace(error, correccion)\n",
    "        \n",
    "    # Filtramos saltos de línea basura\n",
    "    lines = text.split(\"\\n\")\n",
    "    clean_lines = []\n",
    "    for line in lines:\n",
    "        # Si la línea está compuesta solo de guiones, tildes, espacios o está vacía,\n",
    "        # la consideramos basura y la saltamos.\n",
    "        # Ajusta la regex a tus necesidades.\n",
    "        if re.match(r\"^[\\-\\~\\s]+$\", line.strip()):\n",
    "            continue\n",
    "        clean_lines.append(line)\n",
    "\n",
    "    text = \"\\n\".join(clean_lines)\n",
    "    text = re.sub(r\"(?<=\\S)\\n(?=\\S)\", \" \", text)\n",
    "    text = re.sub(r\"\\n{2,}\", \"\\n\\n\", text)\n",
    "    text = re.sub(r\"[ \\t]+\", \" \", text)\n",
    "    text = re.sub(r'(.)\\1{2,}', r'\\1\\1', text)\n",
    "    text = text.strip()\n",
    "    text = re.sub(r\"(No|N°)(\\d+)\", r\"\\1 \\2\", text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r\"(\\d+)([A-Z]{1,3}\\d{4})\", r\"\\1 \\2\", text)\n",
    "    return text\n",
    "\n",
    "def parse_ley_and_type(text: str):\n",
    "    type_map = {\n",
    "        \"orgánica\": \"orgánica\",\n",
    "        \"organica\": \"orgánica\",\n",
    "        \"ordinaria\": \"ordinaria\",\n",
    "        \"estatutaria\": \"estatutaria\",\n",
    "        \"estaturaria\": \"estatutaria\",\n",
    "    }\n",
    "\n",
    "    pattern = r\"\"\"\n",
    "        (?:LEY|LEYES)[\\s\\n]*\n",
    "        (?:\n",
    "            (ORG[ÁA]NICA|ORGANICA|ORDINARIA|ESTATUTARIA|ESTATURARIA)\n",
    "            [\\s\\n]+\n",
    "        )?\n",
    "        (?:N|No|N°|No\\.)?\n",
    "        [\\s\\n]*\n",
    "        (\\d+)\n",
    "    \"\"\"\n",
    "    match = re.search(pattern, text, re.IGNORECASE | re.VERBOSE | re.DOTALL)\n",
    "\n",
    "    if not match:\n",
    "        return (None, None)\n",
    "\n",
    "    raw_type = match.group(1)\n",
    "    ley_number = match.group(2)\n",
    "\n",
    "    if raw_type:\n",
    "        tipo_ley = type_map.get(raw_type.lower())\n",
    "    else:\n",
    "        tipo_ley = None\n",
    "\n",
    "    return (tipo_ley, ley_number)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train epigrafe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1347,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA = [\n",
    "    (\n",
    "        # Ejemplo 1\n",
    "        '2353 17ABR2024 LEY  No. \"POR  MEDIO  DE  LA  CUAL  SE  RECONOCE  COMO  PATRIMONIO '\n",
    "        'CULTURAL  INMATERIAL  DE  LA NACION  EL  FESTIVAL  PROVINCIANO  DE  ACORDEONES,  CANCION '\n",
    "        'INÉDITA  Y  PIQUERIA,  DEL  MUNICIPIO  DE  PIVIJAY  -  MAGDALENA  Y  SE  DICTAN  OTRAS '\n",
    "        'DISPOSICIONES\" El  Congreso  de  Colombia,',\n",
    "        {\"entities\": [\n",
    "            (0, 4, \"NUMERO_LEY\"),         # \"2353\"\n",
    "            (5, 15, \"FECHA\"),              # \"17ABR2024\"\n",
    "            (25, 272, \"EPIGRAFE\")          # desde la apertura de comillas hasta justo antes de \"El Congreso...\"\n",
    "        ]}\n",
    "    ),\n",
    "    (\n",
    "        # Ejemplo 2 (nota: la fecha se compone de \"17MAY\" y \"2024\" separados en el texto; en la anotación se unen)\n",
    "        '2355 2024 LEY  No. 17MAY \"POR  MEDIO  DEL  CUAL  SE  RECONOCE  EL  FESTIVAL  DEPARTAMENTAL '\n",
    "        'DE  BANDAS  DE  CUNDINAMARCA  COMO  MANIFESTACION  DEL  PATRIMONIO  CULTURAL  INMATERIAL '\n",
    "        'DE  LA  NACION\" El  Congreso  de  Colombia,',\n",
    "        {\"entities\": [\n",
    "            (0, 4, \"NUMERO_LEY\"),         # \"2355\"\n",
    "            (5, 9, \"FECHA\"),              # \"2024\" puede interpretarse junto a \"17MAY\" (ver nota abajo)\n",
    "            (19, 24, \"FECHA\"),            # \"17MAY\"\n",
    "            (25, 196, \"EPIGRAFE\")         # epígrafe entre comillas\n",
    "        ]}\n",
    "    ),\n",
    "    (\n",
    "        # Ejemplo 3: La fecha viene separada en tres líneas (\"2356\", \"8\", \"2024\" y luego \"MAY\")\n",
    "        '2356 8 2024 LEY  No. MAY \"POR  MEDIO  DE  LA  CUAL  SE  ELIMINAN  BENEFICIOS  Y  SUBROGADOS '\n",
    "        'PENALES  PARA  QUIENES  SEAN  CONDENADOS  O  ESTÉN  CUMPLIENDO  DETENCION  PREVENTIVA '\n",
    "        'POR  EL  DELITO  DE  FEMINICIDIO\" El  Congreso  de  Colombia,',\n",
    "        {\"entities\": [\n",
    "            (0, 4, \"NUMERO_LEY\"),         # \"2356\"\n",
    "            (5, 6, \"FECHA\"),              # \"8\" (día)\n",
    "            (7, 11, \"FECHA\"),             # \"2024\" (año)\n",
    "            (21, 24, \"FECHA\"),            # \"MAY\" (mes)\n",
    "            (25, 211, \"EPIGRAFE\")\n",
    "        ]}\n",
    "    ),\n",
    "    (\n",
    "        # Ejemplo 4: Uso de \"EL CONGRESO DE LA REPUBLICA DE COLOMBIA\" para marcar el fin del epígrafe\n",
    "        'LEY  No.2361 14JUNZUZ4 POR  MEDIO  DEL  CUAL  SE  OTORGAN  LINEAMIENTOS  PARA  LA '\n",
    "        'CREACION  DE  LA  POLITICA  PUBLICA  DE  LACTANCIA  MATERNA,  ALIMENTACION  COMPLEMENTARIA,  '\n",
    "        'Y  LA  PROMOCION  DE  LOS  BANCOS  DE  LECHE  HUMANA  COMO  COMPONENTE  ANATOMICO  '\n",
    "        'EL  CONGRESO  DE  LA  REPUBLICA  DE  COLOMBIA  DECRETA:',\n",
    "        {\"entities\": [\n",
    "            (8, 12, \"NUMERO_LEY\"),         # \"2361\"\n",
    "            (13, 22, \"FECHA\"),              # \"14JUNZUZ4\" (aquí convendría aplicar correcciones manuales o reglas post-procesado)\n",
    "            (23, 258, \"EPIGRAFE\")           # Desde \"POR MEDIO DE...\" hasta antes de \"EL CONGRESO...\"\n",
    "        ]}\n",
    "    ),\n",
    "    (\n",
    "        # Ejemplo 5: Problema en la fecha \"14JU Te\" y epígrafe sin comillas\n",
    "        '14JU Te LEY  No.  2360 POR  MEDIO  DE  LA  CUAL  SE  MODIFICA  Y  ADICIONA  LA  LEY  1384  DE  2010 '\n",
    "        'RECONOCIENDO  PARA  LOS  EFECTOS  DE  ESTA  LEY  COMO  SUJETOS  DE  ESPECIAL  PROTECCION  CONSTITUCIONAL  A  LAS  '\n",
    "        'PERSONAS  CON SOSPECHA  O  QUE  PADECEN  CANCER EL  CONGRESO  DE  LA  REPUBLICA DECRETA:',\n",
    "        {\"entities\": [\n",
    "            (0, 4, \"FECHA\"),\n",
    "            (18, 22, \"NUMERO_LEY\"),         \n",
    "            (23, 261, \"EPIGRAFE\")\n",
    "        ]}\n",
    "        \n",
    "        # # Ejemplo 5: Problema en la fecha \"14JU Te\" y epígrafe sin comillas\n",
    "        # '8 FEB 2022\\n-\\nLEY ORGÁNICA No2199\\nLEY ORGANICA No2199 FEB 2022 --------~~~~~~~~~--- \"POR MEDIO DE LA CUAL SE DESARROLLA EL ARTÍCULO 325 DE LA \"POR MEDIO DE LA CUAL SE DESARROLLA EL ARTICULO LA CONSTITUCIÓN POLÍTICA Y SE EXPIDE EL RÉGIMEN ESPECIAL DE LA CONSTITUCION POLITICA Y SE EXPIDE EL RÉGIMEN ESPECIAL DE LA REGIÓN METROPOLITANA BOGOTÁ - CUNDINAMARCA\" REGION METROPOLITANA BOGOTA CUNDINAMARCA\" EL CONGRESO DE COLOMBIA EL CONGRESO DE COLOMBIA DECRETA: ',\n",
    "        # {\"entities\": [\n",
    "        #     (0, 4, \"FECHA\"),\n",
    "        #     (18, 22, \"NUMERO_LEY\"),         \n",
    "        #     (23, 261, \"EPIGRAFE\")\n",
    "        # ]}\n",
    "    )\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1348,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example_text = '8 FEB 2022 LEY ORGÁNICA No2199 LEY ORGANICA No2199 FEB 2022 --------~~~~~~~~~--- \"POR MEDIO DE LA CUAL SE DESARROLLA EL ARTÍCULO 325 DE LA \"POR MEDIO DE LA CUAL SE DESARROLLA EL ARTICULO LA CONSTITUCIÓN POLÍTICA Y SE EXPIDE EL RÉGIMEN ESPECIAL DE LA CONSTITUCION POLITICA Y SE EXPIDE EL RÉGIMEN ESPECIAL DE LA REGIÓN METROPOLITANA BOGOTÁ - CUNDINAMARCA\" REGION METROPOLITANA BOGOTA CUNDINAMARCA\" EL CONGRESO DE COLOMBIA EL CONGRESO DE COLOMBIA DECRETA'\n",
    "# print(\"Texto completo:\", example_text)\n",
    "# print(\"Longitud total:\", len(example_text))\n",
    "# print(\"Substring(19,230):\", example_text[25:272])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1349,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_spacy_model(train_data, output_dir=\"modelo_leyes_epigrafe\"):\n",
    "    # Crea un pipeline spaCy en blanco (español)\n",
    "    nlp = spacy.blank(\"es\")\n",
    "    \n",
    "    # Agrega el componente 'ner'\n",
    "    if \"ner\" not in nlp.pipe_names:\n",
    "        ner = nlp.add_pipe(\"ner\", last=True)\n",
    "    else:\n",
    "        ner = nlp.get_pipe(\"ner\")\n",
    "\n",
    "    # Añadir las etiquetas a reconocer\n",
    "    for text, annotations in train_data:\n",
    "        for start, end, label in annotations[\"entities\"]:\n",
    "            ner.add_label(label)\n",
    "\n",
    "    # Inicializar el pipeline\n",
    "    nlp.initialize()\n",
    "\n",
    "    # Crear una lista de Example\n",
    "    examples = []\n",
    "    for text, annotations in train_data:\n",
    "        # Crea un doc a partir del texto\n",
    "        doc = nlp.make_doc(text)\n",
    "        # Crea un Example que contenga el doc y la anotación\n",
    "        example = Example.from_dict(doc, annotations)\n",
    "        examples.append(example)\n",
    "\n",
    "    # Entrenar\n",
    "    for i in range(10):  # número de épocas\n",
    "        random.shuffle(examples)\n",
    "        losses = {}\n",
    "        for example in examples:\n",
    "            nlp.update([example], losses=losses)\n",
    "        print(f\"Época {i}, pérdidas: {losses}\")\n",
    "\n",
    "    # Guardar el modelo entrenado\n",
    "    nlp.to_disk(output_dir)\n",
    "    print(f\"Modelo guardado en: {output_dir}\")\n",
    "\n",
    "    return nlp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1350,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Época 0, pérdidas: {'ner': 296.1709858030081}\n",
      "Época 1, pérdidas: {'ner': 100.17194815090625}\n",
      "Época 2, pérdidas: {'ner': 48.91475365113858}\n",
      "Época 3, pérdidas: {'ner': 106.29416485578864}\n",
      "Época 4, pérdidas: {'ner': 13.568746242703316}\n",
      "Época 5, pérdidas: {'ner': 81.31574794338525}\n",
      "Época 6, pérdidas: {'ner': 218.01332047967202}\n",
      "Época 7, pérdidas: {'ner': 22.61748946640562}\n",
      "Época 8, pérdidas: {'ner': 68.36770297657034}\n",
      "Época 9, pérdidas: {'ner': 11.486735263148187}\n",
      "Modelo guardado en: modelo_leyes_epigrafe\n"
     ]
    }
   ],
   "source": [
    "# Entrenar el modelo con TRAIN_DATA\n",
    "nlp_trained = train_spacy_model(TRAIN_DATA, \"modelo_leyes_epigrafe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargar el modelo entrenado y crear spacy_extract_metadata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1351,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_spacy_model(model_path=\"modelo_leyes_epigrafe\"):\n",
    "    nlp = spacy.load(model_path)\n",
    "    return nlp\n",
    "\n",
    "def spacy_extract_metadata(text: str, nlp) -> dict:\n",
    "    doc = nlp(text)\n",
    "    result = {\n",
    "        \"numero_ley\": None,\n",
    "        \"fecha\": None,\n",
    "        \"epigrafe\": None\n",
    "    }\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ == \"NUMERO_LEY\":\n",
    "            result[\"numero_ley\"] = ent.text\n",
    "        elif ent.label_ == \"FECHA\":\n",
    "            result[\"fecha\"] = ent.text\n",
    "        elif ent.label_ == \"EPIGRAFE\":\n",
    "            result[\"epigrafe\"] = ent.text\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1352,
   "metadata": {},
   "outputs": [],
   "source": [
    "def looks_like_number_ley(value): \n",
    "    # Chequeo rápido: si no hay dígitos, no es un número de ley válido\n",
    "    return bool(re.search(r\"\\d+\", value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1353,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extraer_epigrafe_fallback(text: str, final_fecha: str | None) -> str | None:\n",
    "    \"\"\"\n",
    "    Intenta extraer el epígrafe anclado a la fecha (si la hay).\n",
    "    Si no encuentra nada, hace fallback a la búsqueda sin fecha.\n",
    "    \"\"\"\n",
    "    # 1) Si hay fecha final, probamos la regex anclada a la fecha\n",
    "    if final_fecha:\n",
    "        pattern_with_date = rf\"{re.escape(final_fecha)}.*?(POR\\s+MEDIO\\s+DE\\s+LA\\s+CUAL\\s+.*?)(?:\\.\\s*|\\n|EL\\s+CONGRESO)\"\n",
    "        match = re.search(pattern_with_date, text, re.IGNORECASE | re.DOTALL)\n",
    "        if match:\n",
    "            return match.group(1).strip()\n",
    "\n",
    "    # 2) Fallback: búsqueda sin fecha\n",
    "    pattern_no_date = r\"(POR\\s+MEDIO\\s+DE\\s+LA\\s+CUAL\\s+.*?)(?:\\.\\s*|\\n|EL\\s+CONGRESO)\"\n",
    "    match = re.search(pattern_no_date, text, re.IGNORECASE | re.DOTALL)\n",
    "    if match:\n",
    "        return match.group(1).strip()\n",
    "\n",
    "    # Si ninguno de los dos patrones funcionó, retornamos None\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## function to delete second estructure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1354,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_second_phrase_occurrence(text: str | None, phrase: str) -> str | None:\n",
    "    \"\"\"\n",
    "    Elimina la segunda ocurrencia de `phrase` en `text`.\n",
    "    Si `text` es None, se devuelve None directamente.\n",
    "    \"\"\"\n",
    "    # 1) Si `text` es None o cadena vacía, no hacemos nada.\n",
    "    if not text:\n",
    "        return text\n",
    "\n",
    "    # 2) Procedemos con la lógica de eliminación\n",
    "    text_upper = text.upper()\n",
    "    phrase_upper = phrase.upper()\n",
    "\n",
    "    first_idx = text_upper.find(phrase_upper)\n",
    "    if first_idx == -1:\n",
    "        return text  # No aparece ni una vez\n",
    "\n",
    "    # Buscar segunda ocurrencia a partir del final de la primera\n",
    "    second_idx = text_upper.find(phrase_upper, first_idx + len(phrase))\n",
    "    if second_idx == -1:\n",
    "        return text  # Solo hay una ocurrencia\n",
    "\n",
    "    # Eliminar la segunda ocurrencia (solo la frase en sí)\n",
    "    before = text[:second_idx]\n",
    "    after = text[second_idx + len(phrase):]\n",
    "    return before + after\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## function to extraction spacy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1355,
   "metadata": {},
   "outputs": [],
   "source": [
    "def looks_like_epigrafe(text_epigrafe: str) -> bool:\n",
    "    \"\"\"\n",
    "    Verifica si la cadena `text_epigrafe` cumple criterios mínimos \n",
    "    para considerarse un epígrafe válido.\n",
    "    \"\"\"\n",
    "    if not text_epigrafe:\n",
    "        return False\n",
    "    \n",
    "    # 1) Longitud mínima y máxima (ajusta según tu caso)\n",
    "    #    Por ejemplo, no menos de 30 caracteres ni más de 600.\n",
    "    if len(text_epigrafe) < 30 or len(text_epigrafe) > 600:\n",
    "        return False\n",
    "    \n",
    "    # 2) Que contenga la frase \"POR MEDIO DE\"\n",
    "    #    (en mayúsculas para no depender del case)\n",
    "    if \"POR MEDIO DE\" not in text_epigrafe.upper():\n",
    "        return False\n",
    "    \n",
    "    return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1356,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_metadata_layout_hybrid(text_lineal: str, nlp) -> dict:\n",
    "    text_lineal = fix_ocr_issues(text_lineal)\n",
    "\n",
    "    # 1) spaCy y regex de fecha\n",
    "    spacy_result = spacy_extract_metadata(text_lineal, nlp)\n",
    "    tipo_ley, ley_number = parse_ley_and_type(text_lineal)\n",
    "    fecha_regex = parse_date_str(text_lineal)\n",
    "    spacy_fecha = spacy_result[\"fecha\"]\n",
    "    spacy_fecha_normalizada = normalize_spacy_date(spacy_fecha)\n",
    "\n",
    "    if spacy_fecha_normalizada:\n",
    "        final_fecha = spacy_fecha_normalizada\n",
    "    else:\n",
    "        final_fecha = fecha_regex\n",
    "\n",
    "    # 2) Epígrafe por fallback\n",
    "    epigrafe_regex = extraer_epigrafe_fallback(text_lineal, final_fecha)\n",
    "\n",
    "    # 3) Número de ley (fallback)\n",
    "    spacy_numero_ley = spacy_result[\"numero_ley\"]\n",
    "    if not spacy_numero_ley or not looks_like_number_ley(spacy_numero_ley):\n",
    "        spacy_numero_ley = ley_number\n",
    "\n",
    "    # 4) Epígrafe (fallback spaCy vs regex)\n",
    "    spacy_epigrafe = spacy_result[\"epigrafe\"]\n",
    "    if spacy_epigrafe and looks_like_epigrafe(spacy_epigrafe):\n",
    "        final_epigrafe = spacy_epigrafe\n",
    "    else:\n",
    "        final_epigrafe = epigrafe_regex\n",
    "\n",
    "    # 8) Remover segunda ocurrencia\n",
    "    final_epigrafe = remove_second_phrase_occurrence(final_epigrafe, \"POR MEDIO DE LA CUAL\")\n",
    "\n",
    "\n",
    "    combined = {\n",
    "        \"numero_ley\": spacy_numero_ley,\n",
    "        \"fecha\": final_fecha,\n",
    "        \"tipo_ley\": tipo_ley,\n",
    "        \"epigrafe\": final_epigrafe,\n",
    "    }\n",
    "    return combined\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1357,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_metadata_from_pdf_all_pages(pdf_path: str, nlp=None) -> dict:\n",
    "    \"\"\"\n",
    "    Procesa todas (o varias) páginas del PDF y combina los metadatos \n",
    "    en un único diccionario. \n",
    "    Si encuentra datos faltantes en la primera página, intenta completarlos \n",
    "    en las siguientes.\n",
    "    \"\"\"\n",
    "    # Diccionario final, inicialmente vacío\n",
    "    final_metadata = {\n",
    "        \"numero_ley\": None,\n",
    "        \"fecha\": None,\n",
    "        \"tipo_ley\": None,\n",
    "        \"epigrafe\": None\n",
    "    }\n",
    "\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for page_index, page in enumerate(pdf.pages):\n",
    "            page_text = page.extract_text() or \"\"\n",
    "            page_text = fix_ocr_issues(page_text)\n",
    "\n",
    "            # Extraer metadatos de ESTA página\n",
    "            partial_metadata = extract_metadata_layout_hybrid(page_text, nlp)\n",
    "\n",
    "            # Combinar\n",
    "            # Si 'final_metadata' no tiene un valor, y 'partial_metadata' sí, lo copiamos\n",
    "            for key in final_metadata.keys():\n",
    "                if final_metadata[key] is None and partial_metadata[key] is not None:\n",
    "                    final_metadata[key] = partial_metadata[key]\n",
    "\n",
    "            # (Opcional) Si ya tenemos todos los campos, rompemos el bucle\n",
    "            if all(final_metadata[k] is not None for k in final_metadata):\n",
    "                break\n",
    "\n",
    "    return final_metadata\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## format lecture a pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1358,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_metadata_from_pdf_first_page(pdf_path: str, nlp=None) -> dict:\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        first_page = pdf.pages[0]\n",
    "        page_text = first_page.extract_text() or \"\"\n",
    "\n",
    "    page_text = fix_ocr_issues(page_text)\n",
    "\n",
    "    if nlp:\n",
    "        metadata = extract_metadata_layout_hybrid(page_text, nlp)\n",
    "    else:\n",
    "        metadata = spacy_extract_metadata(page_text)\n",
    "\n",
    "    return metadata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1359,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_text = (\n",
    "#     '2353 17ABR2024 LEY  No. \"POR  MEDIO  DE  LA  CUAL  SE  RECONOCE  COMO  PATRIMONIO '\n",
    "#     'CULTURAL  INMATERIAL  DE  LA NACION  EL  FESTIVAL  PROVINCIANO  DE  ACORDEONES,  CANCION '\n",
    "#     'INÉDITA  Y  PIQUERIA,  DEL  MUNICIPIO  DE  PIVIJAY  -  MAGDALENA  Y  SE  DICTAN  OTRAS '\n",
    "#     'DISPOSICIONES\" El  Congreso  de  Colombia,'\n",
    "# )\n",
    "# doc = nlp_trained(test_text)\n",
    "# for ent in doc.ents:\n",
    "#     print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1360,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leer_pdf_primera_pagina(ruta_pdf: str) -> str:\n",
    "    with pdfplumber.open(ruta_pdf) as pdf:\n",
    "        first_page = pdf.pages[0]\n",
    "        text = first_page.extract_text() or \"\"\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1361,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extraer_metadatos_gaceta_spacy(texto: str) -> dict:\n",
    "    \"\"\"\n",
    "    Envuelve la llamada a tu función híbrida, \n",
    "    para que sea fácil de usar en el bucle de PDFs.\n",
    "    \"\"\"\n",
    "    # Aquí usas la función híbrida con tu modelo entrenado\n",
    "    metadatos = extract_metadata_layout_hybrid(texto, nlp_trained)\n",
    "    return metadatos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1362,
   "metadata": {},
   "outputs": [],
   "source": [
    "def procesar_pdfs_en_carpeta(carpeta_pdf, carpeta_salida):\n",
    "    \"\"\"Procesa todos los archivos PDF en una carpeta y guarda los metadatos en archivos JSON separados.\"\"\"\n",
    "    for archivo in os.listdir(carpeta_pdf):\n",
    "        if archivo.lower().endswith(\".pdf\"):\n",
    "            ruta_pdf = os.path.join(carpeta_pdf, archivo)\n",
    "            \n",
    "            # 1) Lee el PDF (primera página o todas)\n",
    "            texto_pdf = leer_pdf_primera_pagina(ruta_pdf)\n",
    "            # texto_pdf = leer_pdf_todas_paginas(ruta_pdf)  # si quieres todas las páginas\n",
    "            \n",
    "            # 2) Extrae los metadatos con tu pipeline híbrida\n",
    "            metadatos = extraer_metadatos_gaceta_spacy(texto_pdf)\n",
    "            \n",
    "            # 3) Guarda en JSON\n",
    "            nombre_json = os.path.splitext(archivo)[0] + \".json\"\n",
    "            ruta_json = os.path.join(carpeta_salida, nombre_json)\n",
    "            with open(ruta_json, \"w\", encoding=\"utf-8\") as f:\n",
    "                json.dump(metadatos, f, ensure_ascii=False, indent=4)\n",
    "            \n",
    "            print(f\"Metadatos guardados en: {ruta_json}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1363,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadatos guardados en: c:/Users/Jorge/OneDrive/Documents/proyect/document/json_output_2024\\LEY-2199-2022.json\n",
      "Metadatos guardados en: c:/Users/Jorge/OneDrive/Documents/proyect/document/json_output_2024\\LEY-2350-2024.json\n",
      "Metadatos guardados en: c:/Users/Jorge/OneDrive/Documents/proyect/document/json_output_2024\\LEY-2351-2024.json\n",
      "Metadatos guardados en: c:/Users/Jorge/OneDrive/Documents/proyect/document/json_output_2024\\LEY-2352-2024.json\n",
      "Metadatos guardados en: c:/Users/Jorge/OneDrive/Documents/proyect/document/json_output_2024\\LEY-2353-2024.json\n",
      "Metadatos guardados en: c:/Users/Jorge/OneDrive/Documents/proyect/document/json_output_2024\\LEY-2354-2024.json\n",
      "Metadatos guardados en: c:/Users/Jorge/OneDrive/Documents/proyect/document/json_output_2024\\LEY-2355-2024.json\n",
      "Metadatos guardados en: c:/Users/Jorge/OneDrive/Documents/proyect/document/json_output_2024\\LEY-2356-2024.json\n",
      "Metadatos guardados en: c:/Users/Jorge/OneDrive/Documents/proyect/document/json_output_2024\\LEY-2358-2024.json\n",
      "Metadatos guardados en: c:/Users/Jorge/OneDrive/Documents/proyect/document/json_output_2024\\LEY-2359-2024.json\n",
      "Metadatos guardados en: c:/Users/Jorge/OneDrive/Documents/proyect/document/json_output_2024\\LEY-2360-2024.json\n",
      "Metadatos guardados en: c:/Users/Jorge/OneDrive/Documents/proyect/document/json_output_2024\\LEY-2361-2024.json\n",
      "Metadatos guardados en: c:/Users/Jorge/OneDrive/Documents/proyect/document/json_output_2024\\LEY-2364-2024.json\n",
      "Metadatos guardados en: c:/Users/Jorge/OneDrive/Documents/proyect/document/json_output_2024\\LEY-2365-2024.json\n",
      "Metadatos guardados en: c:/Users/Jorge/OneDrive/Documents/proyect/document/json_output_2024\\LEY-2366-2024.json\n",
      "Metadatos guardados en: c:/Users/Jorge/OneDrive/Documents/proyect/document/json_output_2024\\LEY-2367-2024.json\n",
      "Metadatos guardados en: c:/Users/Jorge/OneDrive/Documents/proyect/document/json_output_2024\\LEY-2368-2024.json\n",
      "Metadatos guardados en: c:/Users/Jorge/OneDrive/Documents/proyect/document/json_output_2024\\LEY-2369-2024.json\n",
      "Metadatos guardados en: c:/Users/Jorge/OneDrive/Documents/proyect/document/json_output_2024\\LEY-2373-2024.json\n",
      "Metadatos guardados en: c:/Users/Jorge/OneDrive/Documents/proyect/document/json_output_2024\\LEY-2374-2024.json\n",
      "Metadatos guardados en: c:/Users/Jorge/OneDrive/Documents/proyect/document/json_output_2024\\LEY-2375-2024.json\n",
      "Metadatos guardados en: c:/Users/Jorge/OneDrive/Documents/proyect/document/json_output_2024\\LEY-2376-2024.json\n"
     ]
    }
   ],
   "source": [
    "# --- Ejemplo de Uso --- # 20190620 LEY 1959 # LEY-2199-2022 \n",
    "carpeta_pdf = r\"c:/Users/Jorge/OneDrive/Documents/proyect/document/leyes\"\n",
    "carpeta_salida = r\"c:/Users/Jorge/OneDrive/Documents/proyect/document/json_output_2024\"\n",
    "os.makedirs(carpeta_salida, exist_ok=True)\n",
    "\n",
    "procesar_pdfs_en_carpeta(carpeta_pdf, carpeta_salida)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1364,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pdfplumber\n",
    "\n",
    "# pdf_path = r\"C:\\Users\\Jorge\\OneDrive\\Documents\\proyect\\document\\leyes\\LEY-2199-2022.pdf\"\n",
    "\n",
    "# all_text = \"\"\n",
    "# with pdfplumber.open(pdf_path) as pdf:\n",
    "#     for i, page in enumerate(pdf.pages):\n",
    "#         page_text = page.extract_text() or \"\"\n",
    "#         print(f\"--- Página {i} ---\")\n",
    "#         print(repr(page_text))\n",
    "#         print(\"---------------\")\n",
    "#         all_text += page_text + \"\\n\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Extract",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
