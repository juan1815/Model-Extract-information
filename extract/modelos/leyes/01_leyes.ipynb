{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries ðŸ“š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jorge\\anaconda3\\envs\\Extract\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import fitz\n",
    "import spacy \n",
    "from spacy.matcher import Matcher\n",
    "from  transformers import LayoutLMForTokenClassification, LayoutLMTokenizer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0+cpu\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ---------useðŸ¤–----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LayoutLMForTokenClassification were not initialized from the model checkpoint at microsoft/layoutlm-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Cargar modelo de spaCy\n",
    "nlp = spacy.load(\"es_core_news_sm\")\n",
    "\n",
    "# Cargar modelo de LayoutLM\n",
    "tokenizer = LayoutLMTokenizer.from_pretrained(\"microsoft/layoutlm-base-uncased\")\n",
    "model = LayoutLMForTokenClassification.from_pretrained(\"microsoft/layoutlm-base-uncased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  -------- Functions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fuction with regex ðŸ“Œ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_with_regex(pattern, text):\n",
    "    \"\"\"Extrae informaciÃ³n usando una expresiÃ³n regular.\"\"\"\n",
    "    match = re.search(pattern, text, re.DOTALL)\n",
    "    return match.group(1) if match else \"No encontrado\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to extract text of pdf ðŸ“Œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    text = \"\\n\".join([page.get_text(\"text\") for page in doc])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funtion clean text ðŸ“Œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpiar_texto(texto):\n",
    "    \"\"\"Normaliza y limpia el texto para mejorar la extracciÃ³n de metadatos.\"\"\"\n",
    "    texto = re.sub(r'\\s+', ' ', texto)  # Remueve espacios extra\n",
    "    texto = re.sub(r'[^\\x20-\\x7E\\xC0-\\xFF]', '', texto)  # Remueve caracteres especiales\n",
    "    return texto.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function read a pdf ðŸ“Œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leer_pdf(ruta_pdf):\n",
    "    \"\"\"Lee un archivo PDF y devuelve su contenido en texto limpio.\"\"\"\n",
    "    documento = fitz.open(ruta_pdf)\n",
    "    texto = \"\"\n",
    "    for pagina in documento:\n",
    "        texto += pagina.get_text(\"text\") + \"\\n\"\n",
    "    return limpiar_texto(texto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function from number to whole number ðŸ“Œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def whole_number(romano):\n",
    "    valores = {'M': 1000, 'CM': 900, 'D': 500, 'CD': 400, 'C': 100, 'XC': 90,\n",
    "            'L': 50, 'XL': 40, 'X': 10, 'IX': 9, 'V': 5, 'IV': 4, 'I': 1}\n",
    "    entero = 0\n",
    "    i = 0\n",
    "    while i < len(romano):\n",
    "        if i + 1 < len(romano) and romano[i:i+2] in valores:\n",
    "            entero += valores[romano[i:i+2]]\n",
    "            i += 2\n",
    "        else:\n",
    "            entero += valores[romano[i]]\n",
    "            i += 1\n",
    "    return entero"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete spaces in titles ðŸ“Œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizar_espacios_titulo(texto):\n",
    "    \"\"\"\n",
    "    Corrige textos OCR donde hay espacios innecesarios entre letras en frases clave.\n",
    "    \"\"\"\n",
    "    frases_clave = [\n",
    "        \"SENADO DE LA REPÃšBLICA\",\n",
    "        \"CÃMARA DE REPRESENTANTES\",\n",
    "        \"PROYECTOS DE LEY\"\n",
    "    ]\n",
    "\n",
    "    for frase in frases_clave:\n",
    "        # change the frase\n",
    "        frase_regex = r'\\s*'.join(frase)  # change in \"S\\s*E\\s*N\\s*A\\s*D\\s*O\\s* ...\"\n",
    "        texto = re.sub(frase_regex, frase, texto, flags=re.IGNORECASE)  #remplaze\n",
    "\n",
    "    return texto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Principall function to extract metadata of PDF ðŸ¦â€â¬›"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_metadata_from_pdf(pdf_path):\n",
    "    text = extract_text_from_pdf(pdf_path)\n",
    "    metadata = extract_metadata(text)\n",
    "\n",
    "    # Convertir a JSON\n",
    "    metadata_json = json.dumps(metadata, indent=4, ensure_ascii=False)\n",
    "    return metadata_json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ---------useðŸ¤–----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path = r\"C:\\Users\\Jorge\\OneDrive\\Documents\\proyect\\document\\20160328_XXV_110_64_removed.pdf\"\n",
    "metadata_json = extract_metadata_from_pdf(pdf_path)\n",
    "print(metadata_json)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Extract",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
