{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "import fitz\n",
    "import PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descargar el modelo si no está instalado\n",
    "try:\n",
    "    nlp = spacy.load(\"es_core_news_sm\")\n",
    "except OSError:\n",
    "    from spacy.cli import download\n",
    "    download(\"es_core_news_sm\")\n",
    "    nlp = spacy.load(\"es_core_news_sm\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extraer_info(info_pdf):\n",
    "    \"\"\"Extraer los documento o proyectos que contiene la gaceta\"\"\"\n",
    "    metameta = {}\n",
    "    \n",
    "    try:\n",
    "        with fitz.open(info_pdf) as doc:\n",
    "            texto_completo = \"\"\n",
    "            for pagina in doc:\n",
    "                texto_completo += pagina.get_text()\n",
    "            \n",
    "            texto_completo = preprocesar_texto(texto_completo)\n",
    "\n",
    "            # 1. Nombre Principal\n",
    "            if re.search(r\"(?i)GACETA\\s+DEL\\s+CONGRESO\", texto_completo):\n",
    "                metameta[\"nombre\"] = \"Gaceta del Congreso\"\n",
    "\n",
    "            # --- ISSN ---\n",
    "            metameta[\"issn\"] = extraer_con_regex(r\"I\\s*S\\s*S\\s*N\\s*(0\\s*1\\s*2\\s*3\\s*-\\s*9\\s*0\\s*6\\s*6)\", texto_completo)\n",
    "            if metameta[\"issn\"]:\n",
    "                metameta[\"issn\"] = metameta[\"issn\"].replace(\" \", \"\")\n",
    "\n",
    "            # --- 2. Fecha ---\n",
    "            patron_fecha = r\"(?i)(lunes|martes|miércoles|jueves|viernes|sábado|domingo),\\s*(\\d{1,2})\\s+de\\s+(enero|febrero|marzo|abril|mayo|junio|julio|agosto|septiembre|octubre|noviembre|diciembre)\\s+de\\s+(\\d{4})\"\n",
    "            coincidencia_fecha = re.search(patron_fecha, texto_completo)\n",
    "            if coincidencia_fecha:\n",
    "                meses = {\"enero\": 1, \"febrero\": 2, \"marzo\": 3, \"abril\": 4, \"mayo\": 5, \"junio\": 6,\n",
    "                         \"julio\": 7, \"agosto\": 8, \"septiembre\": 9, \"octubre\": 10, \"noviembre\": 11, \"diciembre\": 12}\n",
    "                dia = int(coincidencia_fecha.group(2))\n",
    "                mes = meses[coincidencia_fecha.group(3).lower()]\n",
    "                anio = int(coincidencia_fecha.group(4))\n",
    "                metameta[\"fecha\"] = f\"{dia:02d}/{mes:02d}/{anio}\"\n",
    "\n",
    "            # 3. Entidad (Senado/Cámara)\n",
    "            match_entity = re.search(r\"(?i)(SENADO Y CÁMARA|SENADO|CÁMARA)\", texto_completo)\n",
    "            if match_entity:\n",
    "                entity = match_entity.group(1).strip()\n",
    "                if entity == \"SENADO Y CÁMARA\":\n",
    "                    metameta[\"entidades\"] = [\"SENADO Y CAMARA\", \"SENADO\", \"CÁMARA\"]\n",
    "                else:\n",
    "                    metameta[\"entidades\"] = [entity]\n",
    "\n",
    "            # --- 4. Año (Números Romanos) y Número de Publicación ---\n",
    "            patron_anio_numero = r\"AÑO\\s+([MDCLXVI]+)\\s*-\\s*N[°º]\\s*(\\d+)\"\n",
    "            coincidencia_anio_numero = re.search(patron_anio_numero, texto_completo, re.IGNORECASE)\n",
    "            if coincidencia_anio_numero:\n",
    "                anio_romano = coincidencia_anio_numero.group(1).strip()\n",
    "                numero_publicacion = coincidencia_anio_numero.group(2).strip()\n",
    "\n",
    "                metameta[\"anio_romano\"] = anio_romano\n",
    "                metameta[\"anio\"] = romano_a_entero(anio_romano)\n",
    "                metameta[\"numero_publicacion\"] = int(numero_publicacion)\n",
    "\n",
    "             # --- 6. Directores (Enfoque Híbrido Robusto) ---\n",
    "            metameta[\"directores\"] = {\"senado\": {}, \"camara\": {}}\n",
    "            patron_directores_inicio = r\"DIRECTORES:\"\n",
    "            coincidencia_inicio = re.search(patron_directores_inicio, texto_completo, re.IGNORECASE)\n",
    "\n",
    "            if coincidencia_inicio:\n",
    "                inicio_seccion = coincidencia_inicio.end()\n",
    "\n",
    "                # Encuentra el final de la sección de directores (más robusto)\n",
    "                fin_seccion = -1\n",
    "                lineas = texto_completo[inicio_seccion:].splitlines()\n",
    "                for i, linea in enumerate(lineas):\n",
    "                    if not re.match(r\"^\\s*[A-ZÁÉÍÓÚÑ\\s.,]+\\s*(SECRETARIO GENERAL DEL SENADO|SECRETARIO GENERAL DE LA CÁMARA|RAMA LEGISLATIVA)?\\s*$\", linea.upper()): #se agrega la ,\n",
    "                        fin_seccion = inicio_seccion + sum(len(l) + 1 for l in lineas[:i])  # +1 por salto de línea\n",
    "                        break\n",
    "\n",
    "                if fin_seccion != -1:\n",
    "                    texto_directores = texto_completo[inicio_seccion:fin_seccion]\n",
    "\n",
    "                    lineas = texto_directores.splitlines()\n",
    "\n",
    "                    # Inicializa variables para guardar nombres y cargos\n",
    "                    nombre_senado = None\n",
    "                    cargo_senado = None\n",
    "                    nombre_camara = None\n",
    "                    cargo_camara = None\n",
    "\n",
    "                    for i in range(len(lineas)):\n",
    "                        linea = lineas[i].strip()\n",
    "                        if not linea: #ignorar lineas vacías\n",
    "                            continue\n",
    "\n",
    "                        if nombre_senado is None and \"SECRETARIO GENERAL DEL SENADO\" not in linea.upper():\n",
    "                            nombre_senado = linea #se obtiene el nombre del senado\n",
    "                        elif cargo_senado is None and \"SECRETARIO GENERAL DEL SENADO\" in linea.upper():\n",
    "                            cargo_senado = \"SECRETARIO GENERAL DEL SENADO\" #cargo del senado\n",
    "                        elif nombre_camara is None and \"SECRETARIO GENERAL DE LA CÁMARA\" not in linea.upper() and cargo_senado is not None: #se valida el cargo senado\n",
    "                            nombre_camara = linea #se obtiene el nombre de la camara\n",
    "                        elif cargo_camara is None and \"SECRETARIO GENERAL DE LA CÁMARA\" in linea.upper():\n",
    "                            cargo_camara = \"SECRETARIO GENERAL DE LA CÁMARA\" #se obtiene el cargo camara\n",
    "\n",
    "                    if nombre_senado and cargo_senado:\n",
    "                        metameta[\"directores\"][\"senado\"][\"nombre\"] = nombre_senado\n",
    "                        metameta[\"directores\"][\"senado\"][\"cargo\"] = cargo_senado\n",
    "                    if nombre_camara and cargo_camara:\n",
    "                        metameta[\"directores\"][\"camara\"][\"nombre\"] = nombre_camara\n",
    "                        metameta[\"directores\"][\"camara\"][\"cargo\"] = cargo_camara\n",
    "                else:\n",
    "                    print(\"No se pudo encontrar el final de la sección de directores.\")\n",
    "\n",
    "                if fin_seccion != -1:\n",
    "                    texto_directores = texto_completo[inicio_seccion:fin_seccion]\n",
    "                    \n",
    "                    lineas = texto_directores.splitlines()\n",
    "                    nombre_senado = None\n",
    "                    cargo_senado = None\n",
    "                    nombre_camara = None\n",
    "                    cargo_camara = None\n",
    "\n",
    "                if texto_directores:\n",
    "                    doc_directores = nlp(texto_directores)\n",
    "\n",
    "                    for ent in doc_directores.ents: # dentro del if\n",
    "                        if ent.label_ == \"PER\":\n",
    "                            nombre = ent.text.strip()\n",
    "                            cargo = None \n",
    "                        \n",
    "                            for sent in doc_directores.sents:\n",
    "                                if nombre in sent.text:\n",
    "                                    for token in sent:\n",
    "                                        if \"SECRETARIO\" in token.text.upper() and \"GENERAL\" in token.text.upper():\n",
    "                                            cargo = token.text\n",
    "                                            if \"SENADO\" in cargo.upper():\n",
    "                                                metameta[\"directores\"][\"senado\"] = {\"nombre\": nombre, \"cargo\": cargo}\n",
    "                                            elif \"CÁMARA\" in cargo.upper():\n",
    "                                                metameta[\"directores\"][\"camara\"] = {\"nombre\": nombre, \"cargo\": cargo}\n",
    "                                            break \n",
    "                                    if cargo:\n",
    "                                        break\n",
    "\n",
    "                                \n",
    "                                \n",
    "            # --- Segundo grupo Documentos (REGEX + Spac) ----\n",
    "            documentos = []\n",
    "            pattern_tipo_documento = r\"(?i)(PROYECTO DE LEY|PROYECTO DE LEY ESTATUTARIA|PROYECTO DE ACTO LEGISLATIVO|PROYECTO DE RESOLUCIÓN|PROYECTO DE ACUERDO|PROYECTO DE ORDENANZA|PROYECTO DE DECRETO|PROYECTO DE RESOLUCIÓN|PROYECTO DE ACUERDO|PROYECTO DE ORDENANZA|PROYECTO DE DECRETO)\"\n",
    "            \n",
    "            for match in re.findeiter(pattern_tipo_documento, texto_completo):\n",
    "                tipo_documento = match.group(1).strip\n",
    "                texto_restante = match.group(2)\n",
    "                \n",
    "                doc_spacy = nlp(texto_restante)\n",
    "                \n",
    "                subtitulo = \"\"\n",
    "                subsubtitulo = \"\"\n",
    "                \n",
    "                #extraer subtitulo (primera linea)\n",
    "                for sent in doc_spacy.sents:\n",
    "                    subtitulo = sent.text.strip()\n",
    "                    if subtitulo:\n",
    "                        break\n",
    "                \n",
    "                # Extraer subtitulo\n",
    "                if subtitulo:\n",
    "                    text_after_subtitle = texto_restante[texto_restante.find(subtitulo) + len(subtitulo):].strip()\n",
    "                    \n",
    "                    # search into   \n",
    "                    match_subsubtitulo  = re.search(r'\"(.*?)\"', text_after_subtitle)\n",
    "                    if match_subsubtitulo:\n",
    "                        subsubtitulo = match_subsubtitulo.group(1)\n",
    "                        \n",
    "                    else: #si no se encuentra entre comillas, buscar la siguiente frase\n",
    "                         for sent in nlp(text_after_subtitle).sents:\n",
    "                            posible_subsubtitulo = sent.text.strip()\n",
    "                            if posible_subsubtitulo:\n",
    "                                subsubtitulo = posible_subsubtitulo\n",
    "                                break\n",
    "                            \n",
    "                documentos.append({\n",
    "                    \"tipo_documento\": tipo_documento,\n",
    "                    \"subtitulo\": subtitulo,\n",
    "                    \"subsubtitulo\": subsubtitulo\n",
    "                })\n",
    "                \n",
    "            metameta[\"documentos\"] = documentos\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: No se pudo encontrar el archivo PDF: {info_pdf}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error al procesar el PDF {info_pdf}: {e}\")\n",
    "        return None\n",
    "            \n",
    "    return metameta\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extraer_con_regex(pattern, text):\n",
    "    coincidencia = re.search(pattern, text)\n",
    "    if coincidencia:\n",
    "        return coincidencia.group(1)\n",
    "    return None\n",
    "\n",
    "def preprocesar_texto(texto):\n",
    "    texto_limpio = re.sub(r\"\\s+\", \" \", texto).strip()  # Elimina espacios extra\n",
    "    texto_limpio = texto_limpio.replace('\\n', ' ')  # elimina saltos de linea\n",
    "    return texto_limpio\n",
    "\n",
    "def leer_pdf(ruta_pdf):\n",
    "    \"\"\"Lee un archivo PDF y devuelve su contenido en texto.\"\"\"\n",
    "    documento = fitz.open(ruta_pdf)\n",
    "    texto = \"\"\n",
    "    for pagina in documento:\n",
    "        texto += pagina.get_text()\n",
    "    return texto\n",
    "\n",
    "def separar_documento(text):\n",
    "    pattern_tipo_documento = r\"(?i)(PONENCIA|ACTA|PROYECTO DE LEY|INFORME|RESOLUCIÓN|CONCEPTO|PROPOSICIÓN|CONSTANCIA|OBJECIONES|CONCEPTOS JURÍDICOS|LEYES SANCIONADAS|PRESENTACIÓN)(.*)\"\n",
    "    documentos = re.findall(pattern_tipo_documento, text)\n",
    "    documentos = [doc[1].strip() for doc in documentos if doc[1].strip()]\n",
    "    \n",
    "    return documentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def romano_a_entero(romano):\n",
    "    valores = {'M': 1000, 'CM': 900, 'D': 500, 'CD': 400, 'C': 100, 'XC': 90,\n",
    "               'L': 50, 'XL': 40, 'X': 10, 'IX': 9, 'V': 5, 'IV': 4, 'I': 1}\n",
    "    entero = 0\n",
    "    i = 0\n",
    "    while i < len(romano):\n",
    "        if i + 1 < len(romano) and romano[i:i+2] in valores:\n",
    "            entero += valores[romano[i:i+2]]\n",
    "            i += 2\n",
    "        else:\n",
    "            entero += valores[romano[i]]\n",
    "            i += 1\n",
    "    return entero\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error al procesar el PDF C:\\Users\\Jorge\\OneDrive\\Documents\\proyect\\document\\20160328_XXV_110_64.pdf: module 're' has no attribute 'findeiter'\n"
     ]
    }
   ],
   "source": [
    "ruta_gaceta = r\"C:\\Users\\Jorge\\OneDrive\\Documents\\proyect\\document\\20160328_XXV_110_64.pdf\"  # Reemplaza con la ruta correcta\n",
    "datos_extraidos = extraer_info(ruta_gaceta) # Pasar la ruta directamente\n",
    "\n",
    "if datos_extraidos:\n",
    "    print(datos_extraidos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # --- Ejemplo de Uso ---\n",
    "# ruta_gaceta = r\"C:\\Users\\Jorge\\OneDrive\\Documents\\proyect\\document\\20160328 XXV 110_64.pdf\"  # Reemplaza con la ruta de tu PDF\n",
    "# texto_prueba = leer_pdf(ruta_gaceta)\n",
    "# datos_extraidos = extraer_info(texto_prueba)\n",
    "\n",
    "# if datos_extraidos:\n",
    "#     print(datos_extraidos)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Extract",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
