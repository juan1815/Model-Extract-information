{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "import fitz\n",
    "\n",
    "# ... (Descargar el modelo de spaCy como lo tenías antes)\n",
    "\n",
    "\n",
    "def extraer_info(ruta_pdf):  # Corregido: Recibir la ruta, no el texto\n",
    "    metadatos = {}  # Cambiado el nombre a metadatos para mayor claridad\n",
    "    \n",
    "    try:   \n",
    "        with fitz.open(ruta_pdf) as doc:\n",
    "            texto_completo = \"\"\n",
    "            for pagina in doc:\n",
    "                texto_completo += pagina.get_text()\n",
    "\n",
    "            texto_completo = preprocesar_texto(texto_completo)\n",
    "\n",
    "            # ... (Código para extraer nombre, ISSN, fecha, entidad, año, rama igual que antes)\n",
    "\n",
    "            # Directores (usando spaCy - Versión ligeramente simplificada)\n",
    "            metadatos[\"directores\"] = {\"senado\": {}, \"camara\": {}}\n",
    "            # ... (Código para encontrar el texto_directores igual que antes)\n",
    "\n",
    "\n",
    "            if texto_directores: # Verificar si texto_directores no está vacío\n",
    "                doc_directores = nlp(texto_directores)\n",
    "\n",
    "                for ent in doc_directores.ents:\n",
    "                    if ent.label_ == \"PER\":\n",
    "                        nombre = ent.text.strip()\n",
    "                        cargo = None # Inicializar cargo dentro del bucle para cada entidad\n",
    "                        # Buscar cargo en la misma frase o en las frases siguientes\n",
    "                        for sent in doc_directores.sents: #sentencias\n",
    "                            if nombre in sent.text: #en las sentencias, se valida si el nombre existe\n",
    "                                for token in sent: #se itera en las sentencias\n",
    "                                    if \"SECRETARIO\" in token.text.upper() and \"GENERAL\" in token.text.upper():\n",
    "                                        cargo = token.text\n",
    "                                        if \"SENADO\" in cargo.upper():\n",
    "                                            metadatos[\"directores\"][\"senado\"] = {\"nombre\": nombre, \"cargo\": cargo}\n",
    "                                        elif \"CÁMARA\" in cargo.upper():\n",
    "                                            metadatos[\"directores\"][\"camara\"] = {\"nombre\": nombre, \"cargo\": cargo}\n",
    "                                        break # Romper el bucle si se encuentra el cargo\n",
    "                \n",
    "                                #si no se ha encontrado el cargo en la frase actual, mirar la siguiente.    \n",
    "                                if cargo:\n",
    "                                    break\n",
    "\n",
    "\n",
    "            # Documentos (combinando regex y spaCy)\n",
    "            documentos = []\n",
    "            pattern_tipo_documento = r\"(?i)(PONENCIA|ACTA|PROYECTO DE LEY|INFORME|RESOLUCIÓN|CONCEPTO|PROPOSICIÓN|CONSTANCIA|OBJECIONES|CONCEPTOS JURÍDICOS|LEYES SANCIONADAS|PRESENTACIÓN)(.*)\"\n",
    "\n",
    "            for match in re.finditer(pattern_tipo_documento, texto_completo):\n",
    "                tipo_documento = match.group(1).strip()\n",
    "                texto_restante = match.group(2)\n",
    "\n",
    "                doc_spacy = nlp(texto_restante)\n",
    "\n",
    "                subtitulo = \"\"\n",
    "                subsubtitulo = \"\"\n",
    "\n",
    "                # Extraer subtítulo (primera línea no vacía)\n",
    "                for sent in doc_spacy.sents:\n",
    "                    subtitulo = sent.text.strip()\n",
    "                    if subtitulo:\n",
    "                        break\n",
    "\n",
    "                # Extraer subsubtítulo (adaptar según la estructura de tus PDFs)\n",
    "                if subtitulo:\n",
    "                    texto_despues_subtitulo = texto_restante[texto_restante.find(subtitulo) + len(subtitulo):].strip()\n",
    "\n",
    "                    # Ejemplo: Buscar entre comillas dobles\n",
    "                    match_subsubtitulo = re.search(r'\"(.*?)\"', texto_despues_subtitulo)\n",
    "                    if match_subsubtitulo:\n",
    "                        subsubtitulo = match_subsubtitulo.group(1)\n",
    "\n",
    "                    else: #si no se encuentra entre comillas, buscar la siguiente frase\n",
    "                         for sent in nlp(texto_despues_subtitulo).sents:\n",
    "                            posible_subsubtitulo = sent.text.strip()\n",
    "                            if posible_subsubtitulo:\n",
    "                                subsubtitulo = posible_subsubtitulo\n",
    "                                break\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                documentos.append({\n",
    "                    \"tipo_documento\": tipo_documento,\n",
    "                    \"subtitulo\": subtitulo,\n",
    "                    \"subsubtitulo\": subsubtitulo\n",
    "                })\n",
    "\n",
    "            metadatos[\"documentos\"] = documentos # Agregar la lista de documentos a metadatos\n",
    "\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: No se pudo encontrar el archivo PDF: {ruta_pdf}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error al procesar el PDF {ruta_pdf}: {e}\")\n",
    "        return None\n",
    "\n",
    "    return metadatos\n",
    "\n",
    "\n",
    "# ... (resto de las funciones auxiliares: extraer_con_regex, preprocesar_texto, romano_a_entero)\n",
    "\n",
    "\n",
    "# --- Ejemplo de Uso ---\n",
    "ruta_gaceta = r\"C:\\Users\\Jorge\\OneDrive\\Documents\\proyect\\document\\20160328 XXV 110_64.pdf\"  # Reemplaza con la ruta correcta\n",
    "datos_extraidos = extraer_info(ruta_gaceta) # Pasar la ruta directamente\n",
    "\n",
    "if datos_extraidos:\n",
    "    print(datos_extraidos)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Extract",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
